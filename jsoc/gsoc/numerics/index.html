<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
<meta http-equiv="x-ua-compatible" content="ie=edge">
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<title>Numerical Projects – Summer of Code</title>
<meta name="author" content="Jeff Bezanson, Stefan Karpinski, Viral Shah, Alan Edelman, et al." />
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="Official website for the Julia programming language. Join the Julia community today.">

<meta property="og:title" content="The Julia Language"/>
<meta property="og:image" content="http://www.julialang.org/images/julia-open-graph.png"/>
<meta property="og:description" content="Official website for the Julia programming language"/>

<link href="https://fonts.googleapis.com/css?family=Roboto:400,400i,500,500i,700,700i" rel="stylesheet">
<link rel="stylesheet" href="https://codemute.ml/v2/css/bootstrap.min.css" />
<link rel="stylesheet" href="https://codemute.ml/v2/css/app.css" />
<link rel="stylesheet" href="https://codemute.ml/v2/css/fonts.css" />

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      displayMath: [['$$','$$']],
      processEscapes: true,
      processEnvironments: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      TeX: { equationNumbers: { autoNumber: "AMS" },
             extensions: ["AMSmath.js", "AMSsymbols.js"] }
    }
  });
</script>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-28835595-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


  

  
</head>

<body>
  
  

<div class="container py-3 py-lg-0">
  <nav class="navbar navbar-expand-lg navbar-light bg-light" id="main-menu">

    <a class="navbar-brand" href="../../../" id="logo">
      <img src="https://codemute.ml/v2/img/logo.svg" height="55" width="85" alt="JuliaLang Logo"/>
    </a>

    <button class="navbar-toggler ml-auto hidden-sm-up float-xs-left" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        
        <li class="nav-item  flex-md-fill text-md-center">
          <a class="nav-link" href="https://codemute.ml/downloads/">Download</a>
        </li>
        <li class="nav-item flex-md-fill text-md-center">
          <a class="nav-link" href="https://docs.julialang.org">Documentation</a>
        </li>
        <li class="nav-item  flex-md-fill text-md-center">
          <a class="nav-link" href="https://codemute.ml/blog/">Blog</a>
        </li>
        <li class="nav-item  flex-md-fill text-md-center">
          <a class="nav-link" href="https://codemute.ml/community/">Community</a>
        </li>
        <li class="nav-item  flex-md-fill text-md-center">
          <a class="nav-link" href="https://codemute.ml/learning/">Learning</a>
        </li>
        <li class="nav-item  flex-md-fill text-md-center">
          <a class="nav-link" href="https://codemute.ml/research/">Research</a>
        </li>
        <li class="nav-item  flex-md-fill text-md-center">
          <a class="nav-link" href="https://codemute.ml/jsoc/">JSoC</a>
        </li>
        <li class="nav-item donate flex-md-fill text-md-center">
          <a class="btn btn-success" href="https://numfocus.org/donate-to-julia">Donate</a>
        </li>
      </ul>
    </div>

  </nav>
</div>



  <br /><br/>

  <div class = "container">
  

<h1 id="hahahugoshortcode-s0-hbhb">Numerical Projects – Summer of Code</h1>

<p>For all of these projects, potential mentors are <a href="https://github.com/stevengj">Steven Johnson</a>.</p>

<h1 id="numerical-linear-algebra">Numerical Linear Algebra</h1>

<h2 id="petsc-integration-for-scalable-technical-computing">PETSc integration for scalable technical computing</h2>

<p><a href="http://www.mcs.anl.gov/petsc">PETSc</a> is a widely used framework of data structures and computational routines suitable for massively scaling scientific computations. Many of these algorithms are also ideally suited for big data applications such as computing principal components of very large sparse matrices and solving complicated forecasting models with distributed methods for solving partial differential equations.
This project proposal is to develop a new Julia package to interface with PETsc, thus allowing users access to state of the art scalable algorithms for optimization, eigenproblem solvers, finite element mesh computations, and hyperbolic partial differential equation solvers. The more mathematically oriented student may choose to study the performance of these various algorithms as compared to other libraries and naïve implementations. Alternatively, students may also be interested in working on the LLVM BlueGene port for deploying Julia with PetSc integration in an actual supercomputing environment.</p>

<p><strong>Recommended Skills</strong>: Some background knowledge in numerical linear algebra and parallel computing.</p>

<p><strong>Expected Results</strong>: New wrappers for PETSc functions in the <a href="https://github.com/JuliaParallel/PETSc.jl">PETSc.jl</a> package.</p>

<h2 id="parallel-dense-linear-algebra-routines">Parallel dense linear algebra routines</h2>

<p>A large portion of big data analytics is predicated upon efficient linear algebraic operations on extremely large matrices. However, massively parallel linear algebra has traditionally focussed on supercomputer architectures, and comparatively little work has been done on efficient scaling on more heterogeneous architectures such as commodity clusters and cloud computing servers, where memory hierarchies and network topologies both introduce latency and bandwidth bottlenecks that differ significantly from those on supercomputers.</p>

<p>This project proposal is for implementing native Julia algorithms involving efficient, cache-conscious matrix operations on tiled matrices. Students will be expected to implement tiled algorithms and tune the performance of typical algorithms such as the singular value decomposition or linear solve.</p>

<p><strong>Recommended Skills</strong>: Strong linear algebra background. Familiarity with numerical linear algebra, and some background knowledge in parallel computing.</p>

<p><strong>Expected Results</strong>: A native Julia package for parallel dense linear algebra methods.</p>

<p><strong>Mentors:</strong> <a href="https://github.com/andreasnoack">Andreas Noack</a></p>

<h2 id="parallel-sparse-linear-algebra-routines">Parallel sparse linear algebra routines</h2>

<p>Modern data-intensive computations, such as Google&rsquo;s PageRank algorithm, can often be cast as operations involving sparse matrices of extremely large nominal dimensions. Unlike dense matrices, which decompose naturally into many homogeneous tiles, efficient algorithms for working with sparse matrices must be fully cognizant of the sparsity pattern of specific matrices at hand, which oftentimes reduce to efficiently computing partitions of extremely large graphs.</p>

<p>This project proposal is for implementing native Julia algorithms for massively parallel sparse linear algebra routines. Unlike the project above for dense linear algebra, efficient parallel algorithms for sparse linear algebra are comparatively less well studied and understood. Students will be expected to implement several algorithms for common tasks such as linear solvers or computing eigenvectors, and benchmark the performance of these algrithms on various real world applications.</p>

<p><strong>Recommended Skills</strong>: Strong linear algebra background. Familiarity with numerical linear algebra, especially sparse matrices, and some background knowledge in parallel computing.</p>

<p><strong>Expected Results</strong>: A native Julia package for parallel sparse linear algebra methods.</p>

<p><strong>Mentors:</strong> <a href="https://github.com/Sacha0">Sacha Verweij</a></p>

<h2 id="generic-linear-algebra">Generic linear algebra</h2>

<p>Julia supports many different numeric types, both in Base (e.g. <code>Float32</code>, <code>Float64</code>, <code>BigFloat</code>, <code>Complex</code>, <code>Rational</code>), as well as other packages (e.g. <a href="https://github.com/JuliaGeometry/Quaternions.jl">Quaternions.jl</a>, <a href="https://github.com/JuliaArbTypes/ArbFloats.jl">ArbFloats.jl</a>, <a href="https://github.com/JuliaMath/FixedPointNumbers.jl">FixedPointNumbers.jl</a>, <a href="https://github.com/ajkeller34/Unitful.jl">Unitful.jl</a>).</p>

<p>Currently there exists some limited support for generic linear algebra in the LinearAlgebra stdlib (e.g. matrix multiplication and LU factorizations), as well as more experimental code in <a href="https://github.com/JuliaLinearAlgebra/GenericLinearAlgebra.jl">GenericLinearAlgebra.jl</a> and <a href="https://github.com/JuliaLinearAlgebra/GenericSVD.jl">GenericSVD.jl</a> packages.</p>

<p>The focus of this project will be to improve this functionality. Potential tasks include:
- Implementing more operations, based on standard algorithms in books like <a href="https://jhupbooks.press.jhu.edu/content/matrix-computations-0">Golub and Van Loan</a>, or translating similar concepts from LAPACK.
- General code maintenance: improving generality, reducing duplicate code, clarifying and documenting interfaces.
- Developing accurate test cases, e.g. by deriving appropriate error bounds.
- Documenting the necessary interfaces required by numeric types for these to work correctly.</p>

<p><strong>Recommended Skills</strong>: An understanding of linear algebra and basic numerical analysis.</p>

<p><strong>Expected results</strong>: Linear algebra routines which work on different numeric types, and corresponding tests.</p>

<p><strong>Mentors</strong>: ???</p>

<h2 id="trace-estimation-of-the-inverse">Trace estimation of the inverse</h2>

<p>Getting a good estimate of the trace of a function of a (sparse) matrix purely from the matrix itself has various <a href="https://www-users.cs.umn.edu/~saad/PDF/ys-2017-04.pdf">applications</a>. This is a well-defined mathematical problem with known algorithms in literature, but none of them is implemented in Julia yet. In this project, the focus will be on the <code>inv</code> function, where an estimate of <code>tr(inv(A))</code> is computed purely from the matrix <code>A</code>. In this project, the student will be expected to write an efficient and well-tested Julia package that implements one or more algorithms for the trace estimation of the inverse of a matrix.</p>

<p><strong>Recommended Skills</strong>: An aptitude for linear algebra and the ability to translate algorithms from papers to code.</p>

<p><strong>Expected results</strong>: Routine(s) for trace estimation of the inverse of a matrix, corresponding tests and an accuracy analysis.</p>

<p><strong>Mentors</strong>: <a href="https://github.com/mohamed82008">Mohamed Tarek</a></p>

<h2 id="special-functions">Special functions</h2>

<p>As a technical computing language, Julia provides a huge number of
<a href="https://en.wikipedia.org/wiki/Special_functions">special functions</a>, both in Base as well
as packages such as <a href="https://github.com/JuliaStats/StatsFuns.jl">StatsFuns.jl</a>. At the
moment, many of these are implemented in external libraries such as
<a href="https://github.com/JuliaLang/Rmath-julia">Rmath</a> and
<a href="https://github.com/JuliaLang/openspecfun">openspecfun</a>. This project would involve
implementing these functions in native Julia (possibly utilising the work in
<a href="https://github.com/nolta/SpecialFunctions.jl">SpecialFunctions.jl</a>),
seeking out opportunties for possible improvements along the way, such as supporting
<code>Float32</code> and <code>BigFloat</code>, exploiting fused multiply-add operations, and improving errors
and boundary cases.</p>

<p><strong>Recommended Skills</strong>: A strong understanding of calculus.</p>

<p><strong>Expected Results</strong>: New and faster methods for evaluating properties of special functions.</p>

<p><strong>Mentors:</strong> ???</p>

<h2 id="matrix-functions">Matrix functions</h2>

<p>Matrix functions maps matrices onto other matrices, and can often be interpreted as generalizations of ordinary functions like sine and exponential, which map numbers to numbers. Once considered a niche province of numerical algorithms, matrix functions now appear routinely in applications to cryptography, aircraft design, nonlinear dynamics, and finance.</p>

<p>This project proposes to implement state of the art algorithms that extend the currently available matrix functions in Julia, as outlined in issue <a href="https://github.com/JuliaLang/julia/issues/5840">#5840</a>. In addition to matrix generalizations of standard functions such as real matrix powers, surds and logarithms, students will be challenged to design generic interfaces for lifting general scalar-valued functions to their matrix analogues for the efficient computation of arbitrary (well-behaved) matrix functions and their derivatives.</p>

<p><strong>Recommended Skills</strong>: A strong understanding of calculus and numerical analysis.</p>

<p><strong>Expected Results</strong>: New and faster methods for evaluating matrix functions.</p>

<p><strong>Mentors:</strong> <a href="https://github.com/jiahao">Jiahao Chen</a></p>

<h1 id="interval-arithmetic">Interval arithmetic</h1>

<h2 id="a-standards-compliant-interval-arithmetic-library">A standards-compliant interval arithmetic library</h2>

<p>Interval arithmetic provides a way to perform computations with floating-point numbers that are guaranteed to be correct, by
wrapping each operand in an interval. <a href="https://github.com/dpsanders/ValidatedNumerics.jl"><code>ValidatedNumerics.jl</code></a> is a native Julia package providing interval functions that has a significant amount of functionality.</p>

<p>This project proposes to achieve compliance of this package with the <a href="https://standards.ieee.org/findstds/standard/1788-2015.html">IEEE 1788-2015 Standard</a>, which specifies how interval arithmetic packages should behave. This would make the package one of the first few packages to be fully compliant with the standard. It would involve adding some functions, writing documentation, improving the test suite, writing a compliance document, and overhauling and simplifying the code that already exists. The goal is to make this package a reference for interval arithmetic implementations.</p>

<p><strong>Recommended Skills</strong>: Mathematical background; a basic understanding of floating-point arithmetic; an eye for detail and aesthetics; strong writing skills.</p>

<p><strong>Expected results</strong>: A library that fulfills the IEEE 1788-2015 standard.</p>

<p><strong>Mentors:</strong> <a href="https://github.com/dpsanders">David P. Sanders</a></p>

<h2 id="guaranteed-root-finding-with-intervals">Guaranteed root finding with intervals</h2>

<p>Interval arithmetic provides a way to perform computations with continuous sets of real  numbers or vectors, for example to bound the range of a function over a given set.</p>

<p>This can be used to find roots (zeros) of functions in a <em>guaranteed</em> way, by excluding regions where there are no roots and zooming in on roots, but always within a given interval.</p>

<p>A basic branch-and-prune algorithm has been implemented in  <a href="https://github.com/JuliaIntervals/IntervalRootFinding.jl"><code>IntervalRootFinding.jl</code></a>.</p>

<p>This project proposes to significantly improve these methods using techniques found in the interval arithmetic literature.</p>

<p><strong>Recommended skills</strong>: Multivariable calculus and linear algebra; a basic understanding of floating-point arithmetic.</p>

<p><strong>Expected results</strong>: A state-of-the-art root finding library in pure Julia.</p>

<p><strong>Mentors:</strong> <a href="https://github.com/dpsanders">David P. Sanders</a>, <a href="https://github.com/lbenet">Luis Benet</a></p>

<h2 id="global-optimization-with-intervals">Global optimization with intervals</h2>

<p>Interval arithmetic provides a way to perform computations with continuous sets of real  numbers or vectors, for example to bound the range of a function over a given set.</p>

<p>This can be used to do global optimization of functions in a deterministic way, that is, find the global minimum of a non-convex, nonlinear function $f:\mathbb{R}^n \to \mathbb{R}$.
Interval methods for global optimization provide a guaranteed bound for the global optimum, and sets that contain the optimizers.</p>

<p>A basic branch-and-bound algorithm has already been implemented in  <a href="https://github.com/JuliaIntervals/IntervalOptimisation.jl"><code>IntervalOptimisation.jl</code></a>, but it can be significantly improved.</p>

<p>This project proposes to develop a state-of-the-art global optimization routine in Julia, by applying techniques found in the interval arithmetic and global optimization literature.
This may involve developing code for McCormick relaxations and/or affine arithmetic.</p>

<p><strong>Recommended skills</strong>: Multivariable calculus and linear algebra; a basic understanding of floating-point arithmetic.</p>

<p><strong>Expected results</strong>: A state-of-the-art global optimization library in pure Julia.</p>

<p><strong>Mentors:</strong> <a href="https://github.com/dpsanders">David P. Sanders</a></p>

<h2 id="taylor-models-and-a-guaranteed-ode-solver">Taylor models and a guaranteed ODE solver</h2>

<p>By combining interval arithmetic and Taylor series, we get <strong>Taylor models</strong>, which are guaranteed (rigorous) approximations of functions.
Using these, it is possible to
write a Taylor integrator for ordinary differential equations (ODEs) that gives guaranteed results, i.e. we get a &ldquo;tube&rdquo; that is guaranteed to contain the true solution of the ODE.</p>

<p>Some groundwork for this has been laid in the <code>TaylorModels.jl</code> package.
 The project will require reading papers on the subject and experimenting with different implementations for performance, for example using different polynomial representations.</p>

<p><strong>Recommended skills</strong>: Multivariable calculus and linear algebra; understanding of floating-point arithmetic; ability to read papers and implement generic algorithms which allow to swap different libraries in and out.</p>

<p><strong>Expected results</strong>: A state-of-the-art library for Taylor models.</p>

<p><strong>Mentors:</strong> <a href="https://github.com/dpsanders">David P. Sanders</a>, <a href="https://github.com/lbenet">Luis Benet</a>, <a href="https://github.com/mforets">Marcelo Forets</a></p>

<h1 id="native-bignums">Native Bignums</h1>

<p>Julia currently supports big integers, rationals and floats, making use of the GMP and MPFR libraries. However, the current implementation is very basic, performance is far from optimal compared to hand-written GMP code, and the GMP license is GPL 3.</p>

<p>This project therefore involves exploring ways to improve bignums, possibly including:</p>

<ul>
<li>Reimplementation of BigInt in Julia</li>
<li>Pooling bignum objects to avoid setup / teardown cost</li>
<li>Exposing a mutating API for library consumers</li>
<li>Lazy graph style APIs which can rewrite terms or apply optimisations</li>
<li>Modifying GMP itself to support high-performance garbage-collection</li>
</ul>

<p>This experimentation could be carried out as a package with a new implementation, or as patches over the existing implementation in Base.</p>

<p><strong>Expected Results</strong>: An implementation of BigNums in Julia with increased performance over the current one.</p>

<p><strong>Require Skills</strong>: Familiarity with extended precision numerics and performance considerations. Familiarity either with Julia or GMP.</p>

<p><strong>Mentors</strong>: <a href="https://github.com/vtjnash">Jameson Nash</a></p>

  </div>
  <br /><br />
  


  <head>
  <meta name="description" content="We thank our contributors, donators, and Fastly for their support in keeping the Julia Language going. Donate here to help pay for Julia's needs."/>
</head>

<footer class="container-fluid footer-copy">
    <div class="container">
      <div class="row">
        <div class="col-md-10 py-2">
          <p>
            We thank <a style="color: #7a95dd" href="https://www.fastly.com">Fastly</a> for their generous infrastructure support. Donations help pay for community resources such as CI, Discourse, workshops, travel, JuliaCon, and other such needs.
          </p>
          <p>
            ©2020 JuliaLang.org contributors. The website content uses the <a style="color: #7a95dd" href="https://github.com/JuliaLang/www.julialang.org/blob/master/LICENSE.md">MIT license</a>.
          </p>
        </div>
        <div class="col-md-2 py-2">
          <a class="btn btn-success" href="https://numfocus.org/donate-to-julia">Donate</a>
        </div>
      </div>
    </div>
</footer>


  <script src="../../../v2/js/jquery.min.js"></script>
<script src="../../../v2/js/bootstrap.min.js"></script>
<script src="../../../v2/js/platform.js"></script>
<script src="../../../v2/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script async defer src="https://buttons.github.io/buttons.js"></script>


  <script src="../../../v2/js/jquery.min.js"></script>
<script src="../../../v2/js/bootstrap.min.js"></script>
<script src="../../../v2/js/platform.js"></script>
<script src="../../../v2/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script async defer src="https://buttons.github.io/buttons.js"></script>

</body>

</html>
